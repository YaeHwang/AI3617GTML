{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6274b702-c968-4950-b0b2-84643aef4a34",
   "metadata": {},
   "source": [
    "# 小作业二： 扩展式博弈、贝叶斯博弈与重复博弈\n",
    "\n",
    "同学们在4-6周课上已经学习了扩展式博弈、贝叶斯博弈与重复博弈。在这次作业中，你们将会回顾之前的知识，并用python来加深对这些博弈的理解。\n",
    "\n",
    "## 目录\n",
    "\n",
    "本次作业主要分为以下几个部分：\n",
    "- 扩展式博弈\n",
    "    - 纳什均衡计算\n",
    "    - 逆向归纳法\n",
    "- 贝叶斯博弈\n",
    "    - 收益矩阵计算\n",
    "    - 均衡求解\n",
    "- 重复博弈\n",
    "    - 环境搭建\n",
    "    - 经典策略实现\n",
    "    - 折现因子$\\delta$的影响\n",
    "\n",
    "## 提交说明：\n",
    "请同学们在canvas上提交，本次作业满分100分，占总成绩15%。\n",
    "\n",
    "**注意，请同学们在提交的版本中不要添加和删改notebook中的函数名，我们会根据这些实现的函数来进行评分。如有其他问题，请联系助教。**\n",
    "\n",
    "提交文件名设置为 `{姓名}_{学号}_hw2.ipynb`，如`小明_123_hw2.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6ee91d-230b-4bd8-bda3-14f71d2bc119",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 扩展式博弈\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72828836-405b-4f23-ae16-499cea86d53f",
   "metadata": {},
   "source": [
    "## 练习一（30分）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543e2db-ba39-412f-8270-8afc47b1b524",
   "metadata": {},
   "source": [
    "1. （15分）在一个简化的poker游戏中，有两名玩家Alice和Bob，牌堆由Ace和King两种类型的牌组成且比例相同。假设他们初始下注都为1。首先，Alice从牌堆抓一张牌(这张牌Alice能看到但Bob不能看到，Bob只知道Alice摸到Ace牌和摸到King牌的概率均为1/2)，然后Alice根据自己摸到的牌决定是加注(+1)还是弃牌(Bob获胜，收益为(-1,1))。如果Alice决定加注，接下来Bob决定是加注(+1)还是弃牌(Alice获胜，收益为(1,-1))。如果Bob决定加注，那么Alice必须展示她抓的牌，如果牌为Ace那么Alice获胜并得到Bob下的注(收益为(2,-2))，反之如果牌为King则Bob获胜并得到Alice下的注(收益为(-2,2))。请用上课讲过的知识计算出上述博弈的纳什均衡策略(P)及对应的收益(R)，并给出Alice选择加注时Bob认为Alice手牌为Ace的belief。\n",
    "\n",
    "Notes：可以参考一下poker的游戏规则。如果Alice摸到King牌，她也不一定要弃牌，因为Bob不知道她是什么牌，只要Bob弃牌那么她依然可以获得胜利。只有当两方都选择加注时，输/赢才会是-2/+2。写策略的时候注意按照[p, 1-p]，p为加注概率来写。\n",
    "\n",
    "请根据问题，把填写以下答案，$P_A$为Alice在纳什均衡点的策略(2 $\\times$ 2的矩阵，第一行为Alice摸到Ace时的策略，第二行为Alice摸到King时的策略)，$R_A$为Alice在纳什均衡点的收益(一个数值)，$P_B$为Bob在纳什均衡点的策略(1 $\\times$ 2的矩阵)，$R_B$为Bob在纳什均衡点的收益。belief为Alice选择加注时Bob认为Alice手牌为Ace的信念(一个概率值)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ba6ad-09f3-4cea-992f-459d3a25fc74",
   "metadata": {},
   "source": [
    "$P_A = [[1, 0], [\\frac{2}{3}, \\frac{1}{3}]], R_A = \\frac{1}{3}$\n",
    "\n",
    "$P_B = [[\\frac{1}{3}, \\frac{2}{3}]], R_B = - \\frac{1}{3}$    \n",
    "\n",
    "$belief = \\frac{3}{5}$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab0266",
   "metadata": {},
   "source": [
    "2. （15分）完成以下代码，使用逆向归纳法求解子博弈精炼纳什均衡。\n",
    "\n",
    "文件\"data.txt\"使用的是第四周课件第95页的博弈，格式解释如下：\n",
    "- Node：通过';'进行拆分\n",
    "    - Node id: 代表是第几号节点\n",
    "    - T/F：是否为叶子节点\n",
    "        - 如果是叶子节点(T)，那么后面跟的是两个玩家的收益，用()表示\n",
    "        - 如果非叶子节点(F)，那么后面跟的是孩子节点的节点序号，用[]表示，最后是一个玩家id表示当前节点是该玩家做决策。\n",
    "        \n",
    "注意：我们可能会在测试的时候更改\"data.txt\"的内容，因此直接print答案是不行的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d3d81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Node     Player  Best Option\n",
      "    0         0         1     \n",
      "    1         1         3     \n",
      "    3         0         6     \n",
      "The payoff is ['3', '2'] in the node 6\n"
     ]
    }
   ],
   "source": [
    "players = 0\n",
    "tree = {}\n",
    "with open(\"data.txt\") as dataFile:\n",
    "    players = int(dataFile.readline().split(\":\")[1].strip())\n",
    "    dataFile.readline()\n",
    "    text = dataFile.readline()\n",
    "    while text != \"\":\n",
    "        arr = text.split(';')\n",
    "        if arr[1] == 'F':\n",
    "            tree[arr[0]] = {'isLeaf': 'F', 'children': arr[2][1:-1].split(','), 'player': int(arr[3].replace(\"\\n\",\"\"))}\n",
    "        elif arr[1] == 'T':\n",
    "            tree[arr[0]] = {'isLeaf': 'T', 'payoffs': arr[2].replace(\"\\n\",\"\")[1:-1].split(',')}\n",
    "        text = dataFile.readline()\n",
    "\n",
    "def induction(node:str):\n",
    "    ### TODO: write your code here ####\n",
    "    ### set nash equilibrium path ###\n",
    "    ### hint: set tree[node]['best'] attribute here\n",
    "    if 'best' not in tree[node].keys():\n",
    "        \n",
    "        if tree[node]['isLeaf'] == 'T':\n",
    "            tree[node]['best'] = [node, tree[node]['payoffs']]\n",
    "        else:\n",
    "            children = tree[node]['children']\n",
    "\n",
    "            for i in children:\n",
    "                induction(i)\n",
    "\n",
    "            payoff_1 = tree[children[0]]['best'][1]\n",
    "            payoff_2 = tree[children[1]]['best'][1]\n",
    "            player = tree[node]['player']\n",
    "\n",
    "            if payoff_1[player] > payoff_2[player]:\n",
    "                tree[node]['best'] = [children[0], payoff_1]\n",
    "            else:\n",
    "                tree[node]['best'] = [children[1], payoff_2]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    \n",
    "\n",
    "def bestStrategy():\n",
    "    msj = f\"{'Node':^10}{'Player':^10}{'Best Option':^10}\\n\"\n",
    "    node = tree['0']\n",
    "    current = 0\n",
    "    while node['isLeaf'] == 'F':\n",
    "        msj += f\"{current:^10}{node['player']:^10}{node['best'][0]:^10}\\n\"\n",
    "        current = node['best'][0]\n",
    "        node = tree[node['best'][0]]\n",
    "    msj += f\"The payoff is {node['best'][1]} in the node {current}\"\n",
    "    return msj\n",
    "\n",
    "induction('0')\n",
    "print(bestStrategy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910c2db-1043-46d2-8fa0-fdd74c23980a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 贝叶斯博弈\n",
    "通过课程的学习，我们知道了一个完整的贝叶斯博弈需要以下要素：\n",
    "- 参与人集合$\\Gamma=\\{1,2,...,n\\}$\n",
    "- 参与人的类型集$T_1,...,T_n$\n",
    "- 参与人关于其他参与人类型的推断$p_1(t_{-1}|t_1),...,p_n(t_{-n}|t_n)$\n",
    "- 参与人类型相依的行动集$A(t_1),...,A(t_n)$\n",
    "- 参与人类型相依的收益函数$u_1(a_1(t_1),a_2(t_2),...,a_n(t_n);t_1),...,u_n(a_1(t_1),a_2(t_2),...,a_n(t_n);t_n)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e12296",
   "metadata": {},
   "source": [
    "在第一节课我们已经学习过了性别之战博弈，在该博弈中我们假设了他们都想共渡一个夜晚而不想分开。然而在实际情况中，该假设不一定总是成立。\n",
    "考虑以下情况：假设男方(玩家2)不一定愿意和女方(玩家1)共渡夜晚，女方不知道男方是否愿意但可以通过贝叶斯规则推断出男方有$\\frac{1}{2}$的概率愿意，有$\\frac{1}{2}$的概率不愿意，两种情况对应的收益矩阵分别为$R^y$和$R^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb8014-b841-4531-a872-f06af01c1132",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{R}^y = \\left[\\begin{matrix}\n",
    "(2,1) & (0,0) \\\\\n",
    "(0,0) & (1,2)\n",
    "\\end{matrix}\\right] \n",
    "\\quad \n",
    "\\mathbf{R}^n = \\left[\\begin{matrix}\n",
    "(2,0) & (0,2) \\\\\n",
    "(0,1) & (1,0)\n",
    "\\end{matrix}\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f4e69",
   "metadata": {},
   "source": [
    "### 练习二 （30分）\n",
    "1.（5分） 请填充以下代码，计算女方(歌剧，歌剧)、(歌剧，拳击)、(拳击，歌剧)、(拳击，拳击)四种纯策略的收益矩阵。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b566ab1-1058-493c-8961-d0cf67dcf050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- If P2 is type 1 ---\n",
      "        B2      S2\n",
      "B1  (2, 1)  (0, 0)\n",
      "S1  (0, 0)  (1, 2)\n",
      "--- If P2 is type 2 ---\n",
      "        B2      S2\n",
      "B1  (2, 0)  (0, 2)\n",
      "S1  (0, 1)  (1, 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "########### TODO: fill in the p: Pr(player 2 is type 1) ###########\n",
    "p = 0.5\n",
    "########### END TODO ##############################################\n",
    "\n",
    "\n",
    "# player 1\n",
    "\n",
    "########### TODO: fill in the payoff matrix of payer 1 ###########\n",
    "u1 = np.array([[2, 0], [0, 1]])\n",
    "########### END TODO #############################################\n",
    "\n",
    "U1 = [u1, u1] # player 1 has same payoffs regardless of 2's type\n",
    "A1 = ['B1', 'S1']\n",
    "\n",
    "# player 2\n",
    "\n",
    "########### TODO: fill in the payoff matrix of payer 2 ###########\n",
    "u21 = np.array([[1, 0], [0, 2]])\n",
    "u22 = np.array([[0, 2], [1, 0]])\n",
    "########### END TODO #############################################\n",
    "\n",
    "\n",
    "U2 = [u21, u22] # player 2 has different payoffs for two types\n",
    "a2 = ['B2', 'S2']\n",
    "A2 = [f'{a[0]}{b[0]}2' for a in a2 for b in a2]\n",
    "\n",
    "def print_payoffs(U, A):\n",
    "    '''\n",
    "        Print payoffs matrix\n",
    "        INPUTS:\n",
    "            U: list of 2 payoff matrices for player 1 (row player) and player 1 for certain state\n",
    "            A: names of actions\n",
    "        OUTPUTS:\n",
    "            t1, t2: payoff matrices suitable for finding the NE\n",
    "            \n",
    "    '''\n",
    "    na1,na2 = U[0].shape\n",
    "    X = [[(U[0][r][c],U[1][r][c]) for c in range(na2)] for r in range(na1)]\n",
    "    payoff_matrix = pd.DataFrame(X, index=A[0], columns=A[1])\n",
    "    return payoff_matrix\n",
    "\n",
    "print(f'--- If P2 is type 1 ---')\n",
    "print(print_payoffs([u1, u21], [A1, a2]))\n",
    "\n",
    "print(f'--- If P2 is type 2 ---')\n",
    "print(print_payoffs([u1, u22], [A1, a2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5426ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- the expected payoffs matrix of player 1 ---\n",
      "    BB2  BS2  SB2  SS2\n",
      "B1  2.0  1.0  1.0  0.0\n",
      "S1  0.0  0.5  0.5  1.0\n",
      "--- the expected payoffs matrix of player 2 ---\n",
      "    BB2  BS2  SB2  SS2\n",
      "B1  0.5  1.5  0.0  1.0\n",
      "S1  0.5  0.0  1.5  1.0\n"
     ]
    }
   ],
   "source": [
    "def expected_payoffs_BoS(U1, U2, p, player=1):\n",
    "    ### TODO: finish this function to get expected payoff\n",
    "    # INPUTS:\n",
    "    #     U1: list of 2 payoff matrices for player 1 (row player)\n",
    "    #     U2: list of 2 payoff matrices for player 2 (column player)\n",
    "    #     p: (scalar) Probability that player 2 is the type 1\n",
    "    #     player: (intager) indicator of player, if player=1 the function return best response of player 1\n",
    "    # OUTPUTS:\n",
    "    #     t1, t2: payoff matrices suitable for finding the NE\n",
    "    #     A1, A2: names of actions\n",
    "    if player == 1:\n",
    "        U = U1\n",
    "    else:\n",
    "        U = U2\n",
    "    \n",
    "    payoff_1 = np.repeat(U[0], 2, axis=1)\n",
    "    payoff_2 = np.concatenate((U[1], U[1]), axis=1)\n",
    "    expected_payoff = payoff_1 * p + payoff_2 * (1-p)\n",
    "    \n",
    "    return expected_payoff\n",
    "\n",
    "# row player: player 1, column player: player 2, \n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 1 ---')\n",
    "X1 = expected_payoffs_BoS(U1, U2, p, 1)\n",
    "print(pd.DataFrame(X1, columns=A2, index=A1))\n",
    "print(f'--- the expected payoffs matrix of player 2 ---') \n",
    "X2 = expected_payoffs_BoS(U1, U2, p, 2)\n",
    "print(pd.DataFrame(X2, columns=A2, index=A1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17725be4-8509-4084-9380-68d709316399",
   "metadata": {},
   "source": [
    "2. （10分）假设男女双方都不一定愿意和对方共渡夜晚，女方通过贝叶斯规则推断出男方有$\\frac{1}{2}$的概率愿意，$\\frac{1}{2}$的概率不愿意；男方通过贝叶斯规则推断出女方有$\\frac{2}{3}$的概率愿意，$\\frac{1}{3}$的概率不愿意，请参考1中例子给出对应的收益矩阵，完成以下代码。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33659d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- each player wants to go out with the other ---\n",
      "        B2      S2\n",
      "B1  (2, 1)  (0, 0)\n",
      "S1  (0, 0)  (1, 2)\n",
      "--- player 1 wants to go out with player 2, but player 2 wants to avoid player 1 ---\n",
      "        B2      S2\n",
      "B1  (2, 0)  (0, 2)\n",
      "S1  (0, 1)  (1, 0)\n",
      "--- player 1 wants to avoid player 2, but player 2 wants to go out with player 1 ---\n",
      "        B2      S2\n",
      "B1  (0, 1)  (2, 0)\n",
      "S1  (1, 0)  (0, 2)\n",
      "--- each player wants to avoid the other ---\n",
      "        B2      S2\n",
      "B1  (0, 0)  (2, 2)\n",
      "S1  (1, 1)  (0, 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# p1: Pr(player 1 think player 2 is type y) p2: Pr(player 2 think player 1 is type y)\n",
    "p1 = 0.5 \n",
    "p2 = 2./3 \n",
    "\n",
    "# player 1\n",
    "\n",
    "########### TODO: fill in the payoff matrix of payer 1 ###########\n",
    "u11 = np.array([[2, 0], [0, 1]])\n",
    "u12 = np.array([[0, 2], [1, 0]])\n",
    "########### END TODO #############################################\n",
    "\n",
    "U1 = [u11, u12] # player 2 has different payoffs for two types\n",
    "a1 = ['B1', 'S1']\n",
    "A1 = [f'{a[0]}{b[0]}1' for a in a1 for b in a1]\n",
    "\n",
    "# player 2\n",
    "\n",
    "########### TODO: fill in the payoff matrix of payer 2 ###########\n",
    "u21 = np.array([[1, 0], [0, 2]])\n",
    "u22 = np.array([[0, 2], [1, 0]])\n",
    "########### END TODO #############################################\n",
    "\n",
    "U2 = [u21, u22] # player 2 has different payoffs for two types\n",
    "a2 = ['B2', 'S2']\n",
    "A2 = [f'{a[0]}{b[0]}2' for a in a2 for b in a2]\n",
    "\n",
    "\n",
    "print(f'--- each player wants to go out with the other ---')\n",
    "print(print_payoffs([u11, u21], [a1, a2]))\n",
    "\n",
    "print(f'--- player 1 wants to go out with player 2, but player 2 wants to avoid player 1 ---')\n",
    "print(print_payoffs([u11, u22], [a1, a2]))\n",
    "\n",
    "print(f'--- player 1 wants to avoid player 2, but player 2 wants to go out with player 1 ---')\n",
    "print(print_payoffs([u12, u21], [a1, a2]))\n",
    "\n",
    "print(f'--- each player wants to avoid the other ---')\n",
    "print(print_payoffs([u12, u22], [a1, a2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ebfb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- the expected payoffs matrix of player 1 type n ---\n",
      "    BB2  BS2  SB2  SS2\n",
      "B1  0.0  1.0  1.0  2.0\n",
      "S1  1.0  0.5  0.5  0.0\n",
      "--- the expected payoffs matrix of player 1 type y ---\n",
      "    BB2  BS2  SB2  SS2\n",
      "B1  2.0  1.0  1.0  0.0\n",
      "S1  0.0  0.5  0.5  1.0\n",
      "--- the expected payoffs matrix of player 2 type n ---\n",
      "    BB1       BS1       SB1  SS1\n",
      "B2  0.0  0.333333  0.666667  1.0\n",
      "S2  2.0  1.333333  0.666667  0.0\n",
      "--- the expected payoffs matrix of player 2 type y ---\n",
      "    BB1       BS1       SB1  SS1\n",
      "B2  1.0  0.666667  0.333333  0.0\n",
      "S2  0.0  0.666667  1.333333  2.0\n"
     ]
    }
   ],
   "source": [
    "def expected_payoffs_BoS(U1, U2, p, player=1, player_type=1):\n",
    "    ################## TODO: calculate expected payoff #########\n",
    "    ###### INPUTS:\n",
    "    ######     U1: list of 2 payoff matrices for player 1 (row player)\n",
    "    ######     U2: list of 2 payoff matrices for player 2 (column player)\n",
    "    ######     p: (scalar) Probability of player\n",
    "    ######     player: (intager) indicator of player, if player=0 the function return best response of player 1\n",
    "    ######     type: (intager) indicator of type, if type=1 denote type n else type=0 denote type y\n",
    "    ###### OUTPUTS:\n",
    "    ######     t1, t2: payoff matrices suitable for finding the NE\n",
    "    ######     A1, A2: names of actions\n",
    "    if player == 1:\n",
    "        U = U1[player_type]\n",
    "    else:\n",
    "        U = U2[player_type].T\n",
    "    \n",
    "    payoff_1 = np.repeat(U, 2, axis=1)\n",
    "    payoff_2 = np.concatenate((U, U), axis=1)\n",
    "    expected_payoff = payoff_1 * p + payoff_2 * (1-p)\n",
    "                \n",
    "    return expected_payoff\n",
    "    #####################################################################################\n",
    "\n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 1 type n ---')\n",
    "X = expected_payoffs_BoS(U1, U2, p1, 1, 1)\n",
    "print(pd.DataFrame(X, columns=A2, index=a1))\n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 1 type y ---')\n",
    "X = expected_payoffs_BoS(U1, U2, p1, 1, 0)\n",
    "print(pd.DataFrame(X, columns=A2, index=a1))\n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 2 type n ---')\n",
    "X = expected_payoffs_BoS(U1, U2, p2, 2, 1)\n",
    "print(pd.DataFrame(X, columns=A1, index=a2))\n",
    "\n",
    "print(f'--- the expected payoffs matrix of player 2 type y ---')\n",
    "X = expected_payoffs_BoS(U1, U2, p2, 2, 0)\n",
    "print(pd.DataFrame(X, columns=A1, index=a2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66092fbb",
   "metadata": {},
   "source": [
    "3. （15分）求解第一问(5')和第二问(10')中博弈的**纯策略贝叶斯纳什均衡**，参考提示（3）的格式将纳什均衡点时的双方纯策略写在下面，如果有多个请全部写出。\n",
    "\n",
    "提示：（1）第一问和第二问的关系有点像“简化的斗鸡博弈”和“斗鸡博弈”之间的关系，需合理利用信念！\n",
    "\n",
    "（2）在静态贝叶斯博弈中策略组合$s^* = (s_1^*,...,s_n^*)$是一个纯策略贝叶斯纳什均衡，如果对$\\forall i \\in T$及$\\forall t_i \\in T_i, s_i^*(t_i)$，满足\n",
    "\n",
    "$s_{i}^{*}\\left(t_{i}\\right) \\in \\arg \\max _{a_{i}\\left(t_{i}\\right) \\in A_{i}\\left(t_{i}\\right)} \\sum_{t_{-i} \\in T_{-i}} u_{i}\\left(s_{1}^{*}\\left(t_{1}\\right), \\cdots, s_{i-1}^{*}\\left(t_{i-1}\\right), a_{i}\\left(t_{i}\\right), s_{i+1}^{*}\\left(t_{i+1}\\right), \\cdots, s_{n}^{*}\\left(t_{n}\\right) ; t_{i}\\right) p_{i}\\left(t_{-i} \\mid t_{i}\\right)$\n",
    "\n",
    "（3）第一问策略类型的格式应为（女方策略，（男方愿意时的策略，男方不愿意时的策略）），第三问策略的格式应为（（女方愿意时策略，女方不愿意时策略），（男方愿意时策略，男方不愿意时策略））"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9eee3",
   "metadata": {},
   "source": [
    "第一问的纳什均衡是: \n",
    "\n",
    "第三问的纳什均衡是:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081c364-6967-4f3b-bf83-c5a1d55531e5",
   "metadata": {},
   "source": [
    "## 重复博弈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3aa2e4",
   "metadata": {},
   "source": [
    "假设两名在进行重复囚徒困境博弈，每个阶段博弈中玩家的收益矩阵为\n",
    "$$\n",
    "\\mathbf{R}^1 = \\left[\\begin{matrix}\n",
    "2 & 0 \\\\\n",
    "3 & 1\n",
    "\\end{matrix}\\right] \n",
    "\\quad \n",
    "\\mathbf{R}^2 = \\left[\\begin{matrix}\n",
    "2 & 3 \\\\\n",
    "0 & 1\n",
    "\\end{matrix}\\right].\n",
    "$$\n",
    "其中第0行/列的动作为抵赖，第1行/列的动作为招供。\\\n",
    "此重复博弈的每个阶段博弈只有一个纳什均衡点(招供，招供)，在课上我们已经学到：阶段博弈重复有限次，在博弈的每个阶段中，博弈的结果都是阶段博弈的纳什均衡，但在无限重复博弈中情况是不同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c34792",
   "metadata": {},
   "source": [
    "### 练习三 （40分）\n",
    "1. （10分）请填充以下代码，搭建重复囚徒困境博弈环境\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86e990f3-104d-49ae-9d17-83e2c92f5f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4570005  -0.62343965]\n",
      " [ 2.19686866  0.84143707]]\n",
      "[[ 1.9010398  -0.34157896]\n",
      " [-0.11514641 -0.33551574]]\n",
      "1 0 2.196868662260708 -0.11514641360093379 {'agent1': [1], 'agent2': [0]} False\n",
      "1 0 2.196868662260708 -0.11514641360093379 {'agent1': [1, 1], 'agent2': [0, 0]} False\n",
      "1 0 2.196868662260708 -0.11514641360093379 {'agent1': [1, 1, 1], 'agent2': [0, 0, 0]} False\n",
      "1 0 2.196868662260708 -0.11514641360093379 {'agent1': [1, 1, 1, 1], 'agent2': [0, 0, 0, 0]} False\n",
      "1 1 0.8414370663572691 -0.33551574358102354 {'agent1': [1, 1, 1, 1, 1], 'agent2': [0, 0, 0, 0, 1]} False\n",
      "0 1 -0.6234396508688526 -0.3415789561576477 {'agent1': [1, 1, 1, 1, 1, 0], 'agent2': [0, 0, 0, 0, 1, 1]} False\n",
      "0 1 -0.6234396508688526 -0.3415789561576477 {'agent1': [1, 1, 1, 1, 1, 0, 0], 'agent2': [0, 0, 0, 0, 1, 1, 1]} False\n",
      "0 1 -0.6234396508688526 -0.3415789561576477 {'agent1': [1, 1, 1, 1, 1, 0, 0, 0], 'agent2': [0, 0, 0, 0, 1, 1, 1, 1]} False\n",
      "1 1 0.8414370663572691 -0.33551574358102354 {'agent1': [1, 1, 1, 1, 1, 0, 0, 0, 1], 'agent2': [0, 0, 0, 0, 1, 1, 1, 1, 1]} False\n",
      "1 1 0.8414370663572691 -0.33551574358102354 {'agent1': [1, 1, 1, 1, 1, 0, 0, 0, 1, 1], 'agent2': [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]} True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class iterated_games():\n",
    "  def __init__(self, payoff1, payoff2, max_step):\n",
    "    self.payoff1 = payoff1\n",
    "    self.payoff2 = payoff2\n",
    "    self.max_step_num = max_step\n",
    "    self.reset()\n",
    "  def reset(self):\n",
    "    self.history = {'agent1':[], 'agent2':[]}\n",
    "    self.step_num = 0\n",
    "    return self.history\n",
    "  def step(self, a1, a2):\n",
    "    ### We recommend that the history can be a dictionary, where each element is a list\n",
    "    ### like self.history['agent1'] = [a11, a12, ...], self.history['agent2']=[a21, a22, ...] defined in the above function\n",
    "    ### So you can directly return self.history\n",
    "\n",
    "    ### input: a1 refers to action for agent 1, a2 refers to action for agent 2\n",
    "    ### TODO: Implement the step function ###\n",
    "    self.step_num += 1\n",
    "\n",
    "    if self.step_num >= self.max_step_num:\n",
    "        done = True\n",
    "    else:\n",
    "        done = False\n",
    "\n",
    "    self.history['agent1'].append(a1)\n",
    "    self.history['agent2'].append(a2)\n",
    "\n",
    "    r1 = self.payoff1[a1, a2]\n",
    "    r2 = self.payoff2[a1, a2]\n",
    "    ### END TODO ###\n",
    "\n",
    "    return r1, r2, self.history, done\n",
    "    # return\n",
    "    # r1: agent1's reward\n",
    "    # r2: agent2's reward\n",
    "    # history: dictionary contains historical information\n",
    "    # done: if step_num reaches max step number, done=True, else done=False\n",
    "\n",
    "### Run some simulations to verify the correctness of your algorithm\n",
    "p1 = np.random.randn(2,2) # two random payoff matrix\n",
    "p2 = np.random.randn(2,2)\n",
    "env = iterated_games(p1, p2, 10)\n",
    "done = False\n",
    "print(p1)\n",
    "print(p2)\n",
    "while True:\n",
    "  if done:\n",
    "    break\n",
    "  a1 = np.random.choice(2)\n",
    "  a2 = np.random.choice(2)\n",
    "  r1, r2, history, done = env.step(a1, a2)\n",
    "  print(a1, a2, r1, r2,history,done)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f1b8d-538d-4452-a8d1-8956c7261439",
   "metadata": {},
   "source": [
    "2. （15分）参考随机策略(random_agent)的写法，在搭建的博弈环境中实现以下三种策略：\n",
    "- 触发策略(grim_trigger_agent): 选择抵赖，但如果对手选择招供，那么接下来每次阶段博弈都选择招供。\n",
    "- 有限惩罚策略(limited_punish_agent)：与触发策略类似，选择抵赖，如果对手选择招供，那么接下来K次博弈都会选择招供(K+1次博弈时会选择抵赖)\n",
    "- 一报还一报策略(tit_for_tat_agent)：总以合作开局，但从此以后就采取以其人之道还治其人之身的策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33453ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test random agent\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "Test grim_trigger_agent, case 1\n",
      "it should be 0 0\n",
      "Test grim_trigger_agent, case 2\n",
      "it should be 1 1\n",
      "Test tit_for_tat_agent, case 1\n",
      "it should be 0 0\n",
      "Test tit_for_tat_agent, case 2\n",
      "it should be 1 1\n"
     ]
    }
   ],
   "source": [
    "### We define the idx for identifying agent because the step function gets the history for both agents\n",
    "### Or you can implement agent in your own ways\n",
    "### Note that you need to handle corner case when the length of history is 0\n",
    "\n",
    "### All agent get input of history dictionary, output the action\n",
    "\n",
    "class random_agent:\n",
    "  def __init__(self, idx=0):\n",
    "    self.idx = idx ### idx for identifying which agent\n",
    "  def step(self, history_both):\n",
    "    action = np.random.choice(2)  \n",
    "    return action\n",
    "\n",
    "class grim_trigger_agent:\n",
    "  def __init__(self, idx=0):\n",
    "    self.idx = idx\n",
    "  def step(self, history_both):\n",
    "    ### TODO: Implement grim trigger agent ###\n",
    "    if self.idx == 0:\n",
    "        history = history_both['agent2']\n",
    "    else:\n",
    "        history = history_both['agent1']\n",
    "    \n",
    "    if 1 in history:\n",
    "        action = 1\n",
    "    else:\n",
    "        action = 0\n",
    "    ### END TODO ###\n",
    "    return action\n",
    "\n",
    "class limited_punish_agent:\n",
    "  def __init__(self, k=3, idx=0):\n",
    "    self.k = k # punishment step\n",
    "    self.idx = idx\n",
    "    ### TODO: Add the variables/functions if you need  ###\n",
    "    self.step_num = 0\n",
    "    ### END TODO  ###\n",
    "  def step(self, history_both):\n",
    "    ### TODO: Implement limited punishment agent ###\n",
    "    ### Note you may need to handle many corner cases:\n",
    "    ### when the agent reverts back to cooperation: have to take cooperation no matter how the other player behaved\n",
    "    ### when the agent is inside the k punishment step\n",
    "    ### when the agent begin to punish\n",
    "    if self.idx == 0:\n",
    "        history = history_both['agent2']\n",
    "    else:\n",
    "        history = history_both['agent1']\n",
    "    \n",
    "    if history[-1] == 1 and len(history) > 0:\n",
    "        action = 1\n",
    "        self.step_num = self.k\n",
    "    elif self.step_num > 0:\n",
    "        action = 1\n",
    "        self.step_num -= 1\n",
    "    else:\n",
    "        action = 0\n",
    "    ### END TODO  ###\n",
    "    return action\n",
    "\n",
    "class tit_for_tat_agent:\n",
    "  def __init__(self, idx=0):\n",
    "    self.idx = idx\n",
    "  def step(self, history_both):\n",
    "    ### TODO: Implement tit for tat ###\n",
    "    if self.idx == 0:\n",
    "        history = history_both['agent2']\n",
    "    else:\n",
    "        history = history_both['agent1']\n",
    "\n",
    "    if len(history) == 0:\n",
    "        action = 0\n",
    "    else:\n",
    "        action = history[-1]    \n",
    "    ### END TODO  ###\n",
    "    return action\n",
    "\n",
    "\n",
    "\n",
    "### Run some simulations to verify the correctness of your algorithm\n",
    "### Random Agent\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [1, 0, 1]}\n",
    "agent = random_agent(idx=0)\n",
    "print('Test random agent')\n",
    "for _ in range(5):\n",
    "  print(agent.step(history))\n",
    "\n",
    "### grim_trigger_agent for testing 2 cases\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [0, 0, 0]}\n",
    "agent = grim_trigger_agent(idx=0)\n",
    "print('Test grim_trigger_agent, case 1')\n",
    "print('it should be', 0, agent.step(history))\n",
    "\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [0, 1, 0]}\n",
    "print('Test grim_trigger_agent, case 2')\n",
    "print('it should be', 1, agent.step(history))\n",
    "\n",
    "### limited_punish_agent for testing\n",
    "### You might define some flag variables in the implementation of limited_punish_agent\n",
    "### So here it might be hard to directly test the correctness\n",
    "### You might need to firstly implement the evaluation function in the next section \n",
    "### Then use that to verify the correctness\n",
    "\n",
    "\n",
    "### tit_for_tat_agent for testing 2 cases\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [0, 1, 0]}\n",
    "agent = tit_for_tat_agent(idx=0)\n",
    "print('Test tit_for_tat_agent, case 1')\n",
    "print('it should be', 0, agent.step(history))\n",
    "\n",
    "history = {'agent1': [1, 0, 0], 'agent2': [0, 1, 1]}\n",
    "print('Test tit_for_tat_agent, case 2')\n",
    "print('it should be', 1, agent.step(history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc64a03",
   "metadata": {},
   "source": [
    "3. （15分）在不同的折现因子$\\delta$情况下，各策略的表现可能不同。在对手采用一报还一报策略的情况下，完善以下代码，画出各策略的相对收益曲线图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af88bbb5-012b-446c-9c29-a3406468c80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_discount_return(return_list, delta):\n",
    "    ### TODO: Implement discount return calculation ###\n",
    "    return_all = 0\n",
    "\n",
    "    for i in reversed(return_list):\n",
    "        return_all = i + delta * return_all\n",
    "    ### END TODO  ###\n",
    "    return return_all\n",
    "\n",
    "def evaluate(env, agent1, agent2, delta):\n",
    "    history = env.reset()\n",
    "    done = False\n",
    "    r1_list = []\n",
    "    r2_list = []\n",
    "    while True:\n",
    "        if done:\n",
    "            break\n",
    "        ### TODO: Implement rollouts ### \n",
    "        ### First take actions for both agent given the history\n",
    "        ### Then take env rollout by env.step based on these two actions\n",
    "        ### Finally, store the reward in r1_list, r2_list\n",
    "        a1 = agent1.step(history)\n",
    "        a2 = agent2.step(history)\n",
    "        r1, r2, history, done = env.step(a1, a2)\n",
    "        r1_list.append(r1)\n",
    "        r2_list.append(r2)\n",
    "        ### END TODO  ###\n",
    "    return1 = get_discount_return(r1_list, delta) # Discounted return for the first policy\n",
    "    return2 = get_discount_return(r2_list, delta) # Discounted return for the second policy\n",
    "    return return1, return2\n",
    "\n",
    "payoff1 = np.array([[2,0],[3,1]])\n",
    "payoff2 = np.array([[2,3],[0,1]])\n",
    "max_step = 100\n",
    "env = iterated_games(payoff1, payoff2, max_step)\n",
    "delta_list = np.linspace(0.01, 0.8, 50)\n",
    "reward_alternate = []\n",
    "reward_all_d = []\n",
    "reward_all_c = []\n",
    "\n",
    "class alternate:\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "        self.step_num = 0\n",
    "    def step(self, history_both):\n",
    "        if self.step_num % 2 == 0:\n",
    "            action = 1\n",
    "        else:\n",
    "            action = 0\n",
    "        self.step_num += 1\n",
    "        return action\n",
    "\n",
    "class all_c:\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "    def step(self, history_both):\n",
    "        action = 0\n",
    "        return action\n",
    "\n",
    "class all_d:\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "    def step(self, history_both):\n",
    "        action = 1\n",
    "        return action\n",
    "\n",
    "for delta in delta_list:\n",
    "    ## TODO: Implement the agent ##\n",
    "    ## Compare the performance between (tit_for_tat_agent, alternate), (tit_for_tat_agent, all_d), (tit_for_tat_agent, all_c)\n",
    "    ## (tit_for_tat_agent, grim_trigger_agent), (tit_for_tat_agent, limited_punish_agent), (tit_for_tat_agent, tit_for_tat_agent)\n",
    "    agent_tit_for_tat = tit_for_tat_agent(idx=0)\n",
    "    agent_alternate = alternate(idx=1)\n",
    "    agent_all_d = all_d(idx=1)\n",
    "    agent_all_c = all_c(idx=1)\n",
    "    r1, r2 = evaluate(env, agent_tit_for_tat, agent_alternate, delta)\n",
    "    r1_1, r2_1 = evaluate(env, agent_tit_for_tat, agent_all_d, delta)\n",
    "    r1_2, r2_2 = evaluate(env, agent_tit_for_tat, agent_all_c, delta)  \n",
    "    ## END TODO ###\n",
    "    reward_alternate.append(r2)\n",
    "    reward_all_d.append(r2_1)\n",
    "    reward_all_c.append(r2_2)\n",
    "  \n",
    "reward_alternate = np.array(reward_alternate)\n",
    "reward_all_d = np.array(reward_all_d)\n",
    "reward_all_c = np.array(reward_all_c)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(delta_list, reward_alternate - reward_all_c, label='alternate')\n",
    "plt.plot(delta_list, reward_all_d - reward_all_c, label='all_defection')\n",
    "plt.plot(delta_list, reward_all_c - reward_all_c, label='all_cooperation')\n",
    "plt.legend()\n",
    "plt.xlabel('Discount factor delta')\n",
    "plt.ylabel('Return difference with all_c policy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
